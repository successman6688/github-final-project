{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05b05641",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2081ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "\n",
    "def process_single_data_dir(data_dir):\n",
    "    \"\"\"\n",
    "    处理单个数据目录（如12kHz_FE_data），返回该目录下B、IR、OR三种故障类型的DataFrame\n",
    "    \n",
    "    参数:\n",
    "        data_dir: 数据目录路径（如D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data）\n",
    "    \n",
    "    返回:\n",
    "        包含三个DataFrame的字典，键为'B', 'IR', 'OR'\n",
    "    \"\"\"\n",
    "    # 初始化存储结果的字典\n",
    "    result_dfs = {\n",
    "        'B': pd.DataFrame(),\n",
    "        'IR': pd.DataFrame(),\n",
    "        'OR': pd.DataFrame()\n",
    "    }\n",
    "    \n",
    "    # 点位映射（仅OR类型需要）\n",
    "    position_mapping = {\n",
    "        \"Orthogonal\": 3,       # 3点钟\n",
    "        \"Centered\": 6,         # 6点钟\n",
    "        \"Opposite\": 12         # 12点钟\n",
    "    }\n",
    "    \n",
    "    # 遍历数据目录下的三种故障类型文件夹（B、IR、OR）\n",
    "    for fault_type in ['B', 'IR', 'OR']:\n",
    "        fault_dir = os.path.join(data_dir, fault_type)\n",
    "        \n",
    "        # 检查文件夹是否存在\n",
    "        if not os.path.exists(fault_dir) or not os.path.isdir(fault_dir):\n",
    "            print(f\"警告：{fault_type}故障类型文件夹不存在或不是目录 - {fault_dir}\")\n",
    "            continue\n",
    "        \n",
    "        all_data = []\n",
    "        print(f\"\\n开始处理 {data_dir} 下的 {fault_type} 类型数据...\")\n",
    "        \n",
    "        # 处理OR类型（有特殊的点位文件夹结构）\n",
    "        if fault_type == 'OR':\n",
    "            # 遍历OR目录下的点位文件夹\n",
    "            for position_folder in os.listdir(fault_dir):\n",
    "                position_path = os.path.join(fault_dir, position_folder)\n",
    "                if not os.path.isdir(position_path):\n",
    "                    continue  # 只处理文件夹\n",
    "                \n",
    "                # 获取点位对应的数字\n",
    "                position_num = position_mapping.get(position_folder, position_folder)\n",
    "                print(f\"处理点位: {position_folder} ({position_num})\")\n",
    "                \n",
    "                # 遍历点位文件夹下的尺寸文件夹\n",
    "                for size_folder in os.listdir(position_path):\n",
    "                    size_path = os.path.join(position_path, size_folder)\n",
    "                    if not os.path.isdir(size_path):\n",
    "                        continue  # 只处理文件夹\n",
    "                    \n",
    "                    # 遍历尺寸文件夹下的MAT文件\n",
    "                    for file_name in os.listdir(size_path):\n",
    "                        if not (file_name.startswith('OR') and file_name.endswith('.mat')):\n",
    "                            continue  # 只处理符合命名规则的MAT文件\n",
    "                        \n",
    "                        file_path = os.path.join(size_path, file_name)\n",
    "                        try:\n",
    "                            # 读取MAT文件\n",
    "                            mat_data = scipy.io.loadmat(file_path)\n",
    "                            \n",
    "                            # 查找X开头的DE_time变量\n",
    "                            pattern = r'X\\d+_DE_time'\n",
    "                            de_time_vars = [var for var in mat_data.keys() if re.match(pattern, var)]\n",
    "                            \n",
    "                            if not de_time_vars:\n",
    "                                print(f\"文件 {file_name} 中未找到符合模式的DE_time变量，跳过\")\n",
    "                                continue\n",
    "                                \n",
    "                            # 取第一个匹配的变量作为基准\n",
    "                            de_time_var = de_time_vars[0]\n",
    "                            id_prefix = de_time_var.split('_')[0]\n",
    "                            \n",
    "                            # 构建其他变量名\n",
    "                            fe_time_var = f\"{id_prefix}_FE_time\"\n",
    "                            rpm_var = f\"{id_prefix}RPM\"\n",
    "                            \n",
    "                            # 验证必要变量是否存在\n",
    "                            required_vars = [de_time_var, fe_time_var, rpm_var]\n",
    "                            missing_vars = [var for var in required_vars if var not in mat_data]\n",
    "                            \n",
    "                            #if missing_vars:\n",
    "                                #print(f\"文件 {file_name} 缺少变量: {', '.join(missing_vars)}，跳过\")\n",
    "                                #continue\n",
    "                            \n",
    "                            # 提取变量数据\n",
    "                            de_time = mat_data[de_time_var].flatten()\n",
    "                            fe_time = mat_data[fe_time_var].flatten()\n",
    "                            rpm = mat_data[rpm_var][0, 0]\n",
    "                            \n",
    "                            # 从文件名提取信息\n",
    "                            file_pattern = r'OR(\\d+)@(\\d+)_(\\d+)\\.mat'\n",
    "                            match = re.match(file_pattern, file_name)\n",
    "                            \n",
    "                            if not match:\n",
    "                                print(f\"文件 {file_name} 命名不符合规则，跳过\")\n",
    "                                continue\n",
    "                            \n",
    "                            fault_size = int(match.group(1))\n",
    "                            load = int(match.group(3))\n",
    "                            \n",
    "                            # 创建DataFrame\n",
    "                            df = pd.DataFrame({\n",
    "                                'DE_time': de_time,\n",
    "                                'FE_time': fe_time,\n",
    "                                'RPM': rpm,\n",
    "                                'fault_type': fault_type,\n",
    "                                'fault_size': fault_size,\n",
    "                                'position': position_num,\n",
    "                                'horsepower': load,\n",
    "                                 'idname':id_prefix\n",
    "                                \n",
    "                            })\n",
    "                            \n",
    "                            all_data.append(df)\n",
    "                            print(f\"成功处理: {file_path}\")\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print(f\"处理文件 {file_path} 时出错: {str(e)}\")\n",
    "        \n",
    "        # 处理B和IR类型\n",
    "        else:\n",
    "            # 遍历故障类型目录下的尺寸文件夹\n",
    "            for folder_name in os.listdir(fault_dir):\n",
    "                folder_path = os.path.join(fault_dir, folder_name)\n",
    "                if not os.path.isdir(folder_path):\n",
    "                    continue  # 只处理文件夹\n",
    "                \n",
    "                # 遍历每个文件夹下的MAT文件\n",
    "                for file_name in os.listdir(folder_path):\n",
    "                    if not (file_name.startswith(fault_type) and file_name.endswith('.mat')):\n",
    "                        continue  # 只处理符合命名规则的MAT文件\n",
    "                    \n",
    "                    file_path = os.path.join(folder_path, file_name)\n",
    "                    try:\n",
    "                        # 读取MAT文件\n",
    "                        mat_data = scipy.io.loadmat(file_path)\n",
    "                        \n",
    "                        # 判断是否为028文件夹\n",
    "                        if folder_name == '0028':\n",
    "                            # 动态识别DE相关变量\n",
    "                            de_vars = [var for var in mat_data.keys() \n",
    "                                      if 'DE' in var and not var.startswith('__')]\n",
    "                            \n",
    "                            if not de_vars:\n",
    "                                de_vars = [var for var in mat_data.keys() \n",
    "                                          if 'de' in var and not var.startswith('__')]\n",
    "                            \n",
    "                            if not de_vars:\n",
    "                                print(f\"028文件夹中文件 {file_name} 未找到包含DE的变量，跳过\")\n",
    "                                continue\n",
    "                            \n",
    "                            # 选择第一个找到的DE相关变量\n",
    "                            de_var = de_vars[0]\n",
    "                            id_prefix=de_var.split('_')[0]\n",
    "                            de_data = mat_data[de_var].flatten()\n",
    "                            \n",
    "                            # 从文件名提取马力和转速\n",
    "                            horsepower_match = re.search(r'_(\\d+)_', file_name)\n",
    "                            rpm_match = re.search(r'\\((\\d+)rpm\\)', file_name)\n",
    "                            \n",
    "                            if not (horsepower_match and rpm_match):\n",
    "                                print(f\"028文件夹中文件 {file_name} 命名不符合规则，跳过\")\n",
    "                                continue\n",
    "                            \n",
    "                            horsepower = int(horsepower_match.group(1))\n",
    "                            rpm = int(rpm_match.group(1))\n",
    "                            \n",
    "                            # 创建DataFrame\n",
    "                            df = pd.DataFrame({\n",
    "                                'DE_time': de_data,\n",
    "                                'fault_type': fault_type,\n",
    "                                'fault_size': int(folder_name),\n",
    "                                'horsepower': horsepower,\n",
    "                                'RPM': rpm,\n",
    "                                'idname':id_prefix\n",
    "                            })\n",
    "                            \n",
    "                        else:\n",
    "                            # 其他文件夹处理逻辑\n",
    "                            pattern = r'X\\d+_DE_time'\n",
    "                            de_time_vars = [var for var in mat_data.keys() if re.match(pattern, var)]\n",
    "                            \n",
    "                            if not de_time_vars:\n",
    "                                print(f\"文件 {file_path} 中未找到符合模式的变量，跳过处理\")\n",
    "                                continue\n",
    "                                \n",
    "                            # 取第一个匹配的变量作为基准\n",
    "                            de_time_var = de_time_vars[0]\n",
    "                            id_prefix = de_time_var.split('_')[0]\n",
    "                            \n",
    "                            # 构建其他变量名\n",
    "                            fe_time_var = f\"{id_prefix}_FE_time\"\n",
    "                            ba_time_var = f\"{id_prefix}_BA_time\"\n",
    "                            rpm_var = f\"{id_prefix}RPM\"\n",
    "                            \n",
    "                            # 验证所有必要变量是否存在\n",
    "                            r_vars = [de_time_var, fe_time_var, ba_time_var, rpm_var]\n",
    "                            required_vars=[var for var in r_vars if var  in mat_data]\n",
    "                            missing_vars = [var for var in r_vars if var not in mat_data]\n",
    "                            \n",
    "                            #if missing_vars:\n",
    "                                #print(f\"文件 {file_path} 缺少变量: {', '.join(missing_vars)}，跳过处理\")\n",
    "                                #continue\n",
    "                            \n",
    "                            # 提取数据\n",
    "                            for i in required_vars:\n",
    "                                if  i==de_time_var:\n",
    "                                    de_time = mat_data[de_time_var].flatten()\n",
    "                                elif i==fe_time_var:\n",
    "                                    fe_time = mat_data[fe_time_var].flatten()   \n",
    "                                elif i==ba_time_var:\n",
    "                                    ba_time = mat_data[ba_time_var].flatten()\n",
    "                                elif i==rpm_var:\n",
    "                                    rpm = mat_data[rpm_var][0, 0]\n",
    "                                \n",
    "                            \n",
    "                            # 从文件名提取马力信息\n",
    "                            horsepower = int(file_name.split('_')[1].split('.')[0])\n",
    "                            \n",
    "                            # 创建DataFrame\n",
    "                            if ba_time_var not in required_vars:\n",
    "                                   \n",
    "                                df = pd.DataFrame({\n",
    "                                    'DE_time': de_time,\n",
    "                                    'FE_time': fe_time,\n",
    "                                    'RPM': rpm,\n",
    "                                    'fault_type': fault_type,\n",
    "                                    'fault_size': int(folder_name),\n",
    "                                    'horsepower': horsepower,\n",
    "                                    'idname':id_prefix\n",
    "                                })\n",
    "                            else:\n",
    "                                df = pd.DataFrame({\n",
    "                                    'DE_time': de_time,\n",
    "                                    'FE_time': fe_time,\n",
    "                                    'BA_time': ba_time,\n",
    "                                    'RPM': rpm,\n",
    "                                    'fault_type': fault_type,\n",
    "                                    'fault_size': int(folder_name),\n",
    "                                    'horsepower': horsepower,\n",
    "                                    'idname':id_prefix\n",
    "                                })\n",
    "\n",
    "                        \n",
    "                        all_data.append(df)\n",
    "                        print(f\"成功处理: {file_path}\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"处理文件 {file_path} 时出错: {str(e)}\")\n",
    "        \n",
    "        # 合并当前故障类型的所有数据\n",
    "        if all_data:\n",
    "            combined_df = pd.concat(all_data, ignore_index=True)\n",
    "            result_dfs[fault_type] = combined_df\n",
    "            \n",
    "            # 保存为CSV文件\n",
    "            output_path = os.path.join(fault_dir, f'combined_{fault_type}_data.csv')\n",
    "            combined_df.to_csv(output_path, index=False)\n",
    "            print(f\"\\n{fault_type}类型数据处理完成！\")\n",
    "            print(f\"合并后的数据形状: {combined_df.shape}\")\n",
    "            print(f\"数据已保存至: {output_path}\")\n",
    "        else:\n",
    "            print(f\"\\n没有成功处理任何{fault_type}类型数据文件\")\n",
    "    \n",
    "    return result_dfs\n",
    "\n",
    "# 使用示例\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa5a473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始处理 D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data 下的 B 类型数据...\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\B\\0007\\B007_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\B\\0007\\B007_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\B\\0007\\B007_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\B\\0007\\B007_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\B\\0014\\B014_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\B\\0014\\B014_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\B\\0014\\B014_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\B\\0014\\B014_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\B\\0021\\B021_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\B\\0021\\B021_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\B\\0021\\B021_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\B\\0021\\B021_3.mat\n",
      "\n",
      "B类型数据处理完成！\n",
      "合并后的数据形状: (1152000, 8)\n",
      "数据已保存至: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\B\\combined_B_data.csv\n",
      "\n",
      "开始处理 D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data 下的 IR 类型数据...\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\IR\\0007\\IR007_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\IR\\0007\\IR007_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\IR\\0007\\IR007_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\IR\\0007\\IR007_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\IR\\0014\\IR014_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\IR\\0014\\IR014_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\IR\\0014\\IR014_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\IR\\0014\\IR014_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\IR\\0021\\IR021_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\IR\\0021\\IR021_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\IR\\0021\\IR021_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\IR\\0021\\IR021_3.mat\n",
      "\n",
      "IR类型数据处理完成！\n",
      "合并后的数据形状: (1152000, 8)\n",
      "数据已保存至: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\IR\\combined_IR_data.csv\n",
      "\n",
      "开始处理 D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data 下的 OR 类型数据...\n",
      "处理点位: Centered (6)\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Centered\\0007\\OR007@6_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Centered\\0007\\OR007@6_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Centered\\0007\\OR007@6_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Centered\\0007\\OR007@6_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Centered\\0014\\OR014@6_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Centered\\0021\\OR021@6_0.mat\n",
      "处理点位: Opposite (12)\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Opposite\\0007\\OR007@12_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Opposite\\0007\\OR007@12_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Opposite\\0007\\OR007@12_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Opposite\\0007\\OR007@12_3.mat\n",
      "处理点位: Orthogonal (3)\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Orthogonal\\0007\\OR007@3_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Orthogonal\\0007\\OR007@3_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Orthogonal\\0007\\OR007@3_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Orthogonal\\0007\\OR007@3_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Orthogonal\\0014\\OR014@3_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Orthogonal\\0014\\OR014@3_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Orthogonal\\0014\\OR014@3_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Orthogonal\\0014\\OR014@3_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Orthogonal\\0021\\OR021@3_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Orthogonal\\0021\\OR021@3_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\Orthogonal\\0021\\OR021@3_3.mat\n",
      "\n",
      "OR类型数据处理完成！\n",
      "合并后的数据形状: (2041168, 8)\n",
      "数据已保存至: D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\\OR\\combined_OR_data.csv\n",
      "生成变量: df_12fe_b，数据形状: (1152000, 8)\n",
      "生成变量: df_12fe_ir，数据形状: (1152000, 8)\n",
      "生成变量: df_12fe_or，数据形状: (2041168, 8)\n",
      "\n",
      "开始处理 D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data 下的 B 类型数据...\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\B\\0007\\B007_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\B\\0007\\B007_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\B\\0007\\B007_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\B\\0007\\B007_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\B\\0014\\B014_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\B\\0014\\B014_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\B\\0014\\B014_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\B\\0014\\B014_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\B\\0021\\B021_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\B\\0021\\B021_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\B\\0021\\B021_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\B\\0021\\B021_3.mat\n",
      "\n",
      "B类型数据处理完成！\n",
      "合并后的数据形状: (2304000, 7)\n",
      "数据已保存至: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\B\\combined_B_data.csv\n",
      "\n",
      "开始处理 D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data 下的 IR 类型数据...\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\IR\\0007\\IR007_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\IR\\0007\\IR007_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\IR\\0007\\IR007_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\IR\\0007\\IR007_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\IR\\0014\\IR014_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\IR\\0014\\IR014_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\IR\\0014\\IR014_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\IR\\0014\\IR014_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\IR\\0021\\IR021_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\IR\\0021\\IR021_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\IR\\0021\\IR021_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\IR\\0021\\IR021_3.mat\n",
      "\n",
      "IR类型数据处理完成！\n",
      "合并后的数据形状: (2175788, 7)\n",
      "数据已保存至: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\IR\\combined_IR_data.csv\n",
      "\n",
      "开始处理 D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data 下的 OR 类型数据...\n",
      "处理点位: Centered (6)\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Centered\\0007\\OR007@6_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Centered\\0007\\OR007@6_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Centered\\0007\\OR007@6_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Centered\\0007\\OR007@6_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Centered\\0014\\OR014@6_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Centered\\0014\\OR014@6_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Centered\\0014\\OR014@6_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Centered\\0014\\OR014@6_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Centered\\0021\\OR021@6_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Centered\\0021\\OR021@6_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Centered\\0021\\OR021@6_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Centered\\0021\\OR021@6_3.mat\n",
      "处理点位: Opposite (12)\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Opposite\\0007\\OR007@12_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Opposite\\0007\\OR007@12_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Opposite\\0007\\OR007@12_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Opposite\\0007\\OR007@12_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Opposite\\0021\\OR021@12_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Opposite\\0021\\OR021@12_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Opposite\\0021\\OR021@12_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Opposite\\0021\\OR021@12_3.mat\n",
      "处理点位: Orthogonal (3)\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Orthogonal\\0007\\OR007@3_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Orthogonal\\0007\\OR007@3_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Orthogonal\\0007\\OR007@3_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Orthogonal\\0007\\OR007@3_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Orthogonal\\0021\\OR021@3_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Orthogonal\\0021\\OR021@3_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Orthogonal\\0021\\OR021@3_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\Orthogonal\\0021\\OR021@3_3.mat\n",
      "\n",
      "OR类型数据处理完成！\n",
      "合并后的数据形状: (5121783, 8)\n",
      "数据已保存至: D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\\OR\\combined_OR_data.csv\n",
      "生成变量: df_48de_b，数据形状: (2304000, 7)\n",
      "生成变量: df_48de_ir，数据形状: (2175788, 7)\n",
      "生成变量: df_48de_or，数据形状: (5121783, 8)\n",
      "\n",
      "开始处理 D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data 下的 B 类型数据...\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\B\\0007\\B007_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\B\\0007\\B007_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\B\\0007\\B007_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\B\\0007\\B007_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\B\\0014\\B014_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\B\\0014\\B014_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\B\\0014\\B014_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\B\\0014\\B014_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\B\\0021\\B021_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\B\\0021\\B021_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\B\\0021\\B021_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\B\\0021\\B021_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\B\\0028\\B028_0_(1797rpm).mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\B\\0028\\B028_1_(1772rpm).mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\B\\0028\\B028_2_(1750rpm).mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\B\\0028\\B028_3_(1730rpm).mat\n",
      "\n",
      "B类型数据处理完成！\n",
      "合并后的数据形状: (1536000, 8)\n",
      "数据已保存至: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\B\\combined_B_data.csv\n",
      "\n",
      "开始处理 D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data 下的 IR 类型数据...\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\IR\\0007\\IR007_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\IR\\0007\\IR007_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\IR\\0007\\IR007_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\IR\\0007\\IR007_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\IR\\0014\\IR014_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\IR\\0014\\IR014_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\IR\\0014\\IR014_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\IR\\0014\\IR014_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\IR\\0021\\IR021_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\IR\\0021\\IR021_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\IR\\0021\\IR021_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\IR\\0021\\IR021_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\IR\\0028\\IR028_0_(1797rpm).mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\IR\\0028\\IR028_1_(1772rpm).mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\IR\\0028\\IR028_2_(1750rpm).mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\IR\\0028\\IR028_3_(1730rpm).mat\n",
      "\n",
      "IR类型数据处理完成！\n",
      "合并后的数据形状: (1536000, 8)\n",
      "数据已保存至: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\IR\\combined_IR_data.csv\n",
      "\n",
      "开始处理 D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data 下的 OR 类型数据...\n",
      "处理点位: Centered (6)\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Centered\\0007\\OR007@6_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Centered\\0007\\OR007@6_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Centered\\0007\\OR007@6_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Centered\\0007\\OR007@6_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Centered\\0014\\OR014@6_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Centered\\0014\\OR014@6_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Centered\\0014\\OR014@6_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Centered\\0014\\OR014@6_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Centered\\0021\\OR021@6_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Centered\\0021\\OR021@6_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Centered\\0021\\OR021@6_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Centered\\0021\\OR021@6_3.mat\n",
      "处理点位: Opposite (12)\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Opposite\\0007\\OR007@12_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Opposite\\0007\\OR007@12_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Opposite\\0007\\OR007@12_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Opposite\\0007\\OR007@12_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Opposite\\0021\\OR021@12_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Opposite\\0021\\OR021@12_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Opposite\\0021\\OR021@12_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Opposite\\0021\\OR021@12_3.mat\n",
      "处理点位: Orthogonal (3)\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Orthogonal\\0007\\OR007@3_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Orthogonal\\0007\\OR007@3_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Orthogonal\\0007\\OR007@3_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Orthogonal\\0007\\OR007@3_3.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Orthogonal\\0021\\OR021@3_0.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Orthogonal\\0021\\OR021@3_1.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Orthogonal\\0021\\OR021@3_2.mat\n",
      "成功处理: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\Orthogonal\\0021\\OR021@3_3.mat\n",
      "\n",
      "OR类型数据处理完成！\n",
      "合并后的数据形状: (2688000, 8)\n",
      "数据已保存至: D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\\OR\\combined_OR_data.csv\n",
      "生成变量: df_12de_b，数据形状: (1536000, 8)\n",
      "生成变量: df_12de_ir，数据形状: (1536000, 8)\n",
      "生成变量: df_12de_or，数据形状: (2688000, 8)\n",
      "\n",
      "12kHz_FE_data的B类型数据前5行:\n",
      "    DE_time   FE_time   BA_time   RPM fault_type  fault_size  horsepower  \\\n",
      "0 -0.061934  0.013047  0.125370  1798          B           7           0   \n",
      "1 -0.038543  0.041502 -0.045680  1798          B           7           0   \n",
      "2 -0.102380  0.023128 -0.104763  1798          B           7           0   \n",
      "3 -0.075578  0.032234  0.123841  1798          B           7           0   \n",
      "4 -0.005731 -0.086788  0.040690  1798          B           7           0   \n",
      "\n",
      "  idname  \n",
      "0   X282  \n",
      "1   X282  \n",
      "2   X282  \n",
      "3   X282  \n",
      "4   X282  \n",
      "\n",
      "48kHz_DE_data的IR类型数据形状: (2175788, 7)\n",
      "\n",
      "合并所有B类型数据后的形状: (4992000, 8)\n"
     ]
    }
   ],
   "source": [
    "# 定义要处理的多个数据目录及其对应的标识（如12FE对应12kHz_FE_data）\n",
    "data_dirs = [\n",
    "    {\n",
    "        \"path\": r\"D:\\360极速浏览器下载\\data\\original\\12kHz_FE_data\",\n",
    "        \"tag\": \"12fe\"  # 数据类型标识（小写，便于变量名）\n",
    "    },\n",
    "    {\n",
    "        \"path\": r\"D:\\360极速浏览器下载\\data\\original\\48kHz_DE_data\",\n",
    "        \"tag\": \"48de\"\n",
    "    },\n",
    "    {\n",
    "        \"path\": r\"D:\\360极速浏览器下载\\data\\original\\12kHz_DE_data\",\n",
    "        \"tag\": \"12de\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 存储所有生成的DataFrame（键为变量名，值为DataFrame）\n",
    "all_dfs = {}\n",
    "\n",
    "# 循环处理每个数据目录\n",
    "for dir_info in data_dirs:\n",
    "    data_path = dir_info[\"path\"]\n",
    "    data_tag = dir_info[\"tag\"]\n",
    "    \n",
    "    # 检查目录是否存在\n",
    "    if not os.path.exists(data_path) or not os.path.isdir(data_path):\n",
    "        print(f\"跳过不存在的目录: {data_path}\")\n",
    "        continue\n",
    "    \n",
    "    # 调用处理函数获取该目录下的三个故障类型DataFrame\n",
    "    fault_dfs = process_single_data_dir(data_path)\n",
    "    \n",
    "    # 为每个故障类型生成带标识的变量名（如df_12fe_b）\n",
    "    for fault_type in ['B', 'IR', 'OR']:\n",
    "        var_name = f\"df_{data_tag}_{fault_type.lower()}\"  # 统一小写，如df_12fe_b\n",
    "        all_dfs[var_name] = fault_dfs[fault_type]\n",
    "        \n",
    "        # 同时生成全局变量（方便直接调用）\n",
    "        globals()[var_name] = fault_dfs[fault_type]\n",
    "        \n",
    "        # 打印生成信息\n",
    "        print(f\"生成变量: {var_name}，数据形状: {fault_dfs[fault_type].shape}\")\n",
    "\n",
    "# ----------------------\n",
    "# 使用示例\n",
    "# ----------------------\n",
    "# 直接使用生成的变量（如12FE的B类型数据）\n",
    "print(\"\\n12kHz_FE_data的B类型数据前5行:\")\n",
    "print(df_12fe_b.head())\n",
    "\n",
    "# 查看48kHz_DE_data的IR类型数据形状\n",
    "print(f\"\\n48kHz_DE_data的IR类型数据形状: {df_48de_ir.shape}\")\n",
    "\n",
    "# 合并同一故障类型的不同数据（如合并所有B类型数据）\n",
    "all_b_dfs = [df for name, df in all_dfs.items() if name.endswith('_b')]\n",
    "combined_b = pd.concat(all_b_dfs, ignore_index=True)\n",
    "print(f\"\\n合并所有B类型数据后的形状: {combined_b.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d13fe4b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "idname",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "count",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "7e9f5746-db64-476f-87d6-e9e38dcd1196",
       "rows": [
        [
         "X282",
         "96000"
        ],
        [
         "X283",
         "96000"
        ],
        [
         "X284",
         "96000"
        ],
        [
         "X285",
         "96000"
        ],
        [
         "X286",
         "96000"
        ],
        [
         "X287",
         "96000"
        ],
        [
         "X288",
         "96000"
        ],
        [
         "X289",
         "96000"
        ],
        [
         "X290",
         "96000"
        ],
        [
         "X291",
         "96000"
        ],
        [
         "X292",
         "96000"
        ],
        [
         "X293",
         "96000"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 12
       }
      },
      "text/plain": [
       "idname\n",
       "X282    96000\n",
       "X283    96000\n",
       "X284    96000\n",
       "X285    96000\n",
       "X286    96000\n",
       "X287    96000\n",
       "X288    96000\n",
       "X289    96000\n",
       "X290    96000\n",
       "X291    96000\n",
       "X292    96000\n",
       "X293    96000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_12fe_b['idname'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba689b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import medfilt, butter, filtfilt, hilbert\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.stats import kurtosis\n",
    "from scipy.ndimage import median_filter\n",
    "# ----------------------\n",
    "# 1. 智能预处理核心函数（脉冲检测+选择性滤波+故障频率带通）\n",
    "# ----------------------\n",
    "def add_sequences(de_seq, fe_seq,ba_seq):\n",
    "                # 取较短序列的长度进行截断，确保对齐\n",
    "     if de_seq and fe_seq and ba_seq:\n",
    "         min_len =min(min(len(de_seq), len(fe_seq)), len(ba_seq))\n",
    "         return  (de_seq[:min_len] + fe_seq[:min_len]+ ba_seq[:min_len] )/3\n",
    "     elif de_seq and fe_seq:\n",
    "            min_len =min(len(de_seq), len(fe_seq))\n",
    "            return  (de_seq[:min_len] + fe_seq[:min_len])/2     # 按元素相加\n",
    "            \n",
    "def moving_average(signal, window_size=5):\n",
    "    return np.convolve(signal, np.ones(window_size)/window_size, mode='same')         \n",
    "def weighted_moving_average(signal, window_size=5):\n",
    "    # 生成高斯权重（中心权重高，边缘低）\n",
    "    weights = np.exp(-0.5 * ((np.arange(window_size) - window_size//2) / (window_size/4))**2)\n",
    "    weights /= np.sum(weights)  # 归一化\n",
    "    return np.convolve(signal, weights, mode='same')\n",
    "def median_filter(signal, size=5):\n",
    "    return median_filter(signal, size=5)   \n",
    "def wavelet_filter(signal, wavelet='db4', level=4):\n",
    "    # 小波去噪\n",
    "    coeffs = pywt.wavedec(signal, wavelet, level=level)\n",
    "    threshold = 0.5 * np.median(np.abs(coeffs[-1]))  # 自适应阈值\n",
    "    coeffs[1:] = [pywt.threshold(c, threshold, 'soft') for c in coeffs[1:]]\n",
    "    return pywt.waverec(coeffs, wavelet)\n",
    "def butter_bandpass_filter(signal, fs, lowcut, highcut, order=4):\n",
    "    # 设计带通滤波器\n",
    "    nyq = 0.5 * fs  # 奈奎斯特频率\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')  # 带通滤波器系数\n",
    "    return filtfilt(b, a, signal) \n",
    "def calculate_ffer(signal, fs, fault_freq, harmonic_order=3):\n",
    "    \"\"\"计算故障频率能量比(FFER)：故障频率及其3次谐波的能量占总能量比例\"\"\"\n",
    "    # 傅里叶变换（取单边谱）\n",
    "    fft_vals = np.fft.fft(signal)\n",
    "    fft_mag = np.abs(fft_vals)[:len(signal)//2]  # 单边幅度谱\n",
    "    freq_axis = np.fft.fftfreq(len(signal), 1/fs)[:len(signal)//2]  # 频率轴\n",
    "\n",
    "    # 总能量\n",
    "    total_energy = np.sum(fft_mag ** 2)\n",
    "    if total_energy < 1e-12:\n",
    "        return 0.0\n",
    "\n",
    "    # 故障频率及谐波的能量总和\n",
    "    fault_energy = 0.0\n",
    "    for n in range(1, harmonic_order + 1):\n",
    "        target_freq = fault_freq * n\n",
    "        # 找到目标频率附近的索引（±1Hz范围，避免频谱泄漏影响）\n",
    "        freq_idx = np.where(np.abs(freq_axis - target_freq) <= 1.0)[0]\n",
    "        if len(freq_idx) > 0:\n",
    "            fault_energy += np.sum(fft_mag[freq_idx] ** 2)\n",
    "    \n",
    "    return fault_energy / total_energy\n",
    "def calculate_sample_entropy(signal, m=2, r=0.2):\n",
    "    \"\"\"计算样本熵（衡量信号复杂度，故障信号复杂度更高）\n",
    "    - m: 嵌入维度，默认2\n",
    "    - r: 相似容差，默认0.2*信号标准差\n",
    "    \"\"\"\n",
    "    signal = np.array(signal)\n",
    "    n = len(signal)\n",
    "    if n < m + 1:\n",
    "        return 0.0  # 数据长度不足时返回0\n",
    "    \n",
    "    # 计算相似容差（默认0.2*标准差）\n",
    "    r = r * np.std(signal) if r < 1 else r\n",
    "    \n",
    "    # 构建m维和m+1维嵌入矩阵\n",
    "    def _embed(x, dim):\n",
    "        return np.array([x[i:i+dim] for i in range(len(x) - dim + 1)])\n",
    "    \n",
    "    mat_m = _embed(signal, m)\n",
    "    mat_m1 = _embed(signal, m + 1)\n",
    "    \n",
    "    # 计算相似向量数\n",
    "    def _count_similar(mat, r_val):\n",
    "        count = 0\n",
    "        for i in range(len(mat)):\n",
    "            # 计算与其他向量的最大距离\n",
    "            dist = np.max(np.abs(mat - mat[i]), axis=1)\n",
    "            # 统计小于等于r的向量数（排除自身）\n",
    "            count += np.sum(dist <= r_val) - 1\n",
    "        return count / (len(mat) - 1)  # 归一化\n",
    "    \n",
    "    c_m = _count_similar(mat_m, r)\n",
    "    c_m1 = _count_similar(mat_m1, r)\n",
    "    \n",
    "    # 避免log(0)\n",
    "    if c_m == 0 or c_m1 == 0:\n",
    "        return 0.0\n",
    "    return -np.log(c_m1 / c_m)\n",
    "def calculate_permutation_entropy(signal, m=3, tau=1):\n",
    "    \"\"\"计算排列熵（衡量信号时序模式复杂度）\n",
    "    - m: 嵌入维度，默认3\n",
    "    - tau: 延迟时间，默认1\n",
    "    \"\"\"\n",
    "    signal = np.array(signal)\n",
    "    n = len(signal)\n",
    "    if n < m * tau:\n",
    "        return 0.0\n",
    "    \n",
    "    # 构建嵌入矩阵\n",
    "    mat = np.array([signal[i:i+m*tau:tau] for i in range(n - m*tau + 1)])\n",
    "    # 对每行排序并记录索引（排列模式）\n",
    "    permutations = np.argsort(mat, axis=1)\n",
    "    # 统计每种排列模式的出现频率\n",
    "    unique_perms, counts = np.unique(permutations, axis=0, return_counts=True)\n",
    "    probs = counts / len(permutations)\n",
    "    \n",
    "    # 计算排列熵（避免log(0)）\n",
    "    return -np.sum(probs * np.log2(probs + 1e-12))\n",
    "def calculate_harmonic_energy_ratio(signal, fs, fault_freq, max_harmonic=5):\n",
    "    \"\"\"计算物理域特征：故障频率倍数能量比（检测谐波/边带）\"\"\"\n",
    "    # 傅里叶变换\n",
    "    fft_mag = np.abs(np.fft.fft(signal))[:len(signal)//2]\n",
    "    freq_axis = np.fft.fftfreq(len(signal), 1/fs)[:len(signal)//2]\n",
    "    total_energy = np.sum(fft_mag ** 2)\n",
    "    if total_energy < 1e-12:\n",
    "        return np.zeros(max_harmonic)  # 能量过小时返回全0\n",
    "    \n",
    "    # 计算各次谐波的能量比\n",
    "    harmonic_ratios = []\n",
    "    for n in range(1, max_harmonic + 1):\n",
    "        target_freq = fault_freq * n\n",
    "        # 捕捉目标频率±0.5Hz范围（提高准确性）\n",
    "        freq_idx = np.where(np.abs(freq_axis - target_freq) <= 0.5)[0]\n",
    "        if len(freq_idx) == 0:\n",
    "            harmonic_ratios.append(0.0)\n",
    "        else:\n",
    "            harmonic_energy = np.sum(fft_mag[freq_idx] ** 2)\n",
    "            harmonic_ratios.append(harmonic_energy / total_energy)\n",
    "    \n",
    "    return harmonic_ratios\n",
    "def calculate_envelope_features(signal, fs):\n",
    "    \"\"\"计算包络域特征：包络谱峰值 + 包络峭度\"\"\"\n",
    "    # 1. 希尔伯特变换求解析信号（包络）\n",
    "    analytic_signal = hilbert(signal)\n",
    "    envelope = np.abs(analytic_signal)\n",
    "    \n",
    "    # 2. 包络峭度（去均值避免直流分量影响）\n",
    "    envelope_kurt = kurtosis(envelope - np.mean(envelope), fisher=False)  # \n",
    "    \n",
    "    # 3. 包络谱峰值（对包络做FFT找峰值）\n",
    "    envelope_fft = np.abs(np.fft.fft(envelope))[:len(envelope)//2]\n",
    "    envelope_freq = np.fft.fftfreq(len(envelope), 1/fs)[:len(envelope)//2]\n",
    "    # 排除0Hz直流分量\n",
    "    valid_idx = envelope_freq > 1.0  # 忽略1Hz以下低频干扰\n",
    "    if np.sum(valid_idx) == 0:\n",
    "        envelope_peak = 0.0\n",
    "    else:\n",
    "        envelope_peak = np.max(envelope_fft[valid_idx])\n",
    "    \n",
    "    return envelope_peak, envelope_kurt\n",
    "def smart_preprocess(signal, fs, rpm, fault_type, bearing_type,threshold=3.0, kernel_size=5):\n",
    "    \"\"\"对单条振动信号执行智能预处理，输入为numpy数组\"\"\"\n",
    "    sig = signal.copy()\n",
    "    \n",
    "    # 步骤1：检测大幅值脉冲（故障冲击特征）\n",
    "    if detect_pulses(sig, threshold):\n",
    "        # 步骤2：轻度中值滤波（保留脉冲，滤除高频噪声）\n",
    "        sig = light_median_filter(sig, kernel_size)\n",
    "    \n",
    "    # 步骤3：故障频率带通滤波（聚焦目标故障频率附近信号）\n",
    "    center_freq = calculate_fault_frequency(rpm, fault_type, bearing_type)\n",
    "    nyq = 0.5 * fs  # 奈奎斯特频率，避免频率超界\n",
    "    lowcut = max(10, center_freq - 200)  # 滤波下限（不低于10Hz）\n",
    "    highcut = min(nyq - 10, center_freq + 200)  # 滤波上限（不超过奈奎斯特-10Hz）\n",
    "    sig = bandpass_filter(sig, fs, lowcut, highcut)\n",
    "    \n",
    "    return sig\n",
    "\n",
    "# ----------------------\n",
    "# 2. 辅助函数（工具类）\n",
    "# ----------------------\n",
    "def detect_pulses(signal, threshold=3.0):\n",
    "    \"\"\"脉冲检测：超过均值±threshold*标准差的视为脉冲\"\"\"\n",
    "    mean_val = np.mean(signal)\n",
    "    std_val = np.std(signal)\n",
    "    return np.any(np.abs(signal - mean_val) > threshold * std_val)\n",
    "\n",
    "def light_median_filter(signal, kernel_size=5):\n",
    "    \"\"\"轻度中值滤波，kernel_size建议为奇数（5/7）\"\"\"\n",
    "    return medfilt(signal, kernel_size=kernel_size)\n",
    "\n",
    "\n",
    "def calculate_fault_frequency(rpm, fault_type, bearing_type):\n",
    "    \"\"\"\n",
    "    适配不同轴承类型的故障特征频率计算\n",
    "    bearing_type: 'DE'（对应SKF6205）或 'FE'（对应SKF6203）\n",
    "    \"\"\"\n",
    "    # 轴承参数：滚动体数N_d, 滚动体直径d, 轴承节径D（单位：英寸）\n",
    "    if bearing_type == 'DE':\n",
    "        N_d, d, D = 9, 0.3126, 1.537\n",
    "    else:  # FE\n",
    "        N_d, d, D = 9, 0.2656, 1.122\n",
    "    \n",
    "    f_r = rpm / 60  # 轴承转频（Hz）\n",
    "    \n",
    "    if fault_type == 'OR':  # 外圈故障（BPFO）\n",
    "        return (N_d / 2) * f_r * (1 - d/D)\n",
    "    elif fault_type == 'IR':  # 内圈故障（BPFI）\n",
    "        return (N_d / 2) * f_r * (1 + d/D)\n",
    "    elif fault_type == 'B':  # 滚动体故障（BSF）\n",
    "        return (D / d) * f_r * (1 - (d/D)**2)\n",
    "    else:\n",
    "        return 1000  # 未知故障默认频率\n",
    "\n",
    "def bandpass_filter(signal, fs, lowcut, highcut, order=4):\n",
    "    \"\"\"零相位带通滤波（避免信号相位偏移）\"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')  # Butterworth滤波器\n",
    "    return filtfilt(b, a, signal)  # filtfilt实现零相位\n",
    "\n",
    "def extract_time_features(signal):\n",
    "    \"\"\"提取时域特征（故障识别核心特征）\"\"\"\n",
    "    signal_abs = np.abs(signal)\n",
    "    return pd.Series({\n",
    "        \"mean\": np.mean(signal),\n",
    "        \"var\": np.var(signal),\n",
    "        \"std\": np.std(signal),\n",
    "        \"kurtosis\": pd.Series(signal).kurtosis(),  # 峭度（对冲击敏感）\n",
    "        \"peak\": np.max(signal_abs),  # 峰值\n",
    "        \"rms\": np.sqrt(np.mean(signal**2)),  # 均方根（能量指标）\n",
    "        \"peak_factor\": np.max(signal_abs) / np.sqrt(np.mean(signal**2)),  # 峰值因子\n",
    "        \"Margin_Factor\":np.max(signal) / (np.sqrt(np.mean(signal)) ** 2 + 1e-8)\n",
    "    })\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=4):\n",
    "    \"\"\"低频滤波器，用于提取BA信号中的低频成分\"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "def extract_envelope_features(signal, fs):\n",
    "    \"\"\"提取包络域特征\"\"\"\n",
    "    envelope_peak, envelope_kurt = calculate_envelope_features(signal, fs)\n",
    "    return pd.Series({\n",
    "        \"envelope_peak\": envelope_peak,\n",
    "        \"envelope_kurtosis\": envelope_kurt\n",
    "    })\n",
    "def extract_sample_entropy(signal):\n",
    "    \"\"\"提取样本熵特征\"\"\"\n",
    "    sampen = calculate_sample_entropy(signal)\n",
    "    perpen=calculate_permutation_entropy(signal) \n",
    "    return pd.Series({\n",
    "        \"sample_entropy\": sampen,\n",
    "        \"permutation_entropy\": perpen\n",
    "    })\n",
    "\n",
    "def extract_physical_features(signal, fs, rpm, fault_type, bearing_type):\n",
    "    \"\"\"提取物理特征\"\"\"\n",
    "    features={}\n",
    "    fault_freq = calculate_fault_frequency(rpm, fault_type, bearing_type)\n",
    "    harmonic_ratios=calculate_harmonic_energy_ratio(signal, fs, fault_freq)\n",
    "    for n, ratio in enumerate(harmonic_ratios, 1):\n",
    "        features[f\"ffer_harmonic_{n}\"] = ratio\n",
    "    return pd.Series(features)\n",
    "    \n",
    "def extract_frequency_features(signal, fs, rpm):\n",
    "    \"\"\"提取频域特征，特别关注BA信号的低频特征\"\"\"\n",
    "    n = len(signal)\n",
    "    freq = np.fft.fftfreq(n, 1/fs)[:n//2]\n",
    "    fft_values = np.abs(np.fft.fft(signal))[:n//2]\n",
    "    \n",
    "    # 计算旋转频率 (1x RPM)\n",
    "    rotation_freq = rpm / 60\n",
    "    \n",
    "    # 提取关键频率成分的幅值\n",
    "    features = {\n",
    "        'fft_max': np.max(fft_values),\n",
    "        'fft_mean': np.mean(fft_values),\n",
    "        'rotation_freq_amp': np.max(fft_values[np.where((freq >= rotation_freq*0.9) & (freq <= rotation_freq*1.1))]),\n",
    "        'double_rotation_amp': np.max(fft_values[np.where((freq >= rotation_freq*1.9) & (freq <= rotation_freq*2.1))]),\n",
    "        'triple_rotation_amp': np.max(fft_values[np.where((freq >= rotation_freq*2.9) & (freq <= rotation_freq*3.1))]),\n",
    "        'low_freq_energy': np.sum(fft_values[np.where(freq <= 100)]) / np.sum(fft_values) if np.sum(fft_values) > 0 else 0,  # <100Hz 能量占比\n",
    "        'mid_low_freq_energy': np.sum(fft_values[np.where((freq > 100) & (freq <= 500))]) / np.sum(fft_values) if np.sum(fft_values) > 0 else 0  # 100-500Hz 能量占比\n",
    "    }\n",
    "    return pd.Series(features)\n",
    "# ----------------------\n",
    "# 3. 核心：按idname分组+智能预处理（适配动态信号列）\n",
    "# ----------------------\n",
    "def preprocess_df(df, data_tag, fs):\n",
    "    \"\"\"\n",
    "    对单个DataFrame（如df_12fe_b）执行完整预处理：\n",
    "    - 自动检测存在的信号列（DE_time/FE_time/BA_time）\n",
    "    - 按idname分组处理（保证同类有序数据一致性）\n",
    "    - 只处理存在的信号列，不存在的跳过\n",
    "    \"\"\"\n",
    "    # 步骤1：检测当前DataFrame中存在的信号列\n",
    "    signal_cols = []\n",
    "    if \"DE_time\" in df.columns:\n",
    "        signal_cols.append(\"DE_time\")\n",
    "    if \"FE_time\" in df.columns:\n",
    "        signal_cols.append(\"FE_time\")\n",
    "    if \"BA_time\" in df.columns:\n",
    "        signal_cols.append(\"BA_time\")\n",
    "    \n",
    "    if not signal_cols:\n",
    "        print(f\"警告：{data_tag} 无任何信号列，返回空DataFrame\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # 步骤2：按idname分组处理（同一idname为一类有序数据）\n",
    "    grouped_results = []\n",
    "    id_scaler_dict = {}  # 存储每个idname的标准化器（保证同组参数一致）\n",
    "    \n",
    "    for idname, group_df in df.groupby(\"idname\"):\n",
    "        print(f\"处理 {data_tag} - idname: {idname}（数据量: {group_df.shape[0]}）\")\n",
    "        \n",
    "        # 子步骤1：缺失值处理（关键列不可缺）\n",
    "        drop_na_cols = signal_cols + [\"RPM\", \"fault_type\", \"idname\"]\n",
    "        group_df = group_df.dropna(subset=drop_na_cols)\n",
    "        if group_df.empty:\n",
    "            print(f\"idname {idname} 无有效数据，跳过\")\n",
    "            continue\n",
    "        \n",
    "        # 子步骤2：对存在的信号列逐个执行智能预处理\n",
    "        processed_signal_cols = []\n",
    "        for col in signal_cols:\n",
    "            proc_col = f\"{col}_processed\"  # 处理后列名（如DE_time→DE_time_processed）\n",
    "            processed_signal_cols.append(proc_col)\n",
    "            \n",
    "            # 逐行处理（每行RPM/fault_type可能不同，需动态适配）\n",
    "            group_df[proc_col] = group_df.apply(\n",
    "                    lambda row: smart_preprocess(\n",
    "                        signal=row[col],  # 原始信号（已为numpy数组）\n",
    "                        fs=fs,            # 采样率（根据数据类型确定）\n",
    "                        rpm=row[\"RPM\"],   # 当前样本的转速\n",
    "                        fault_type=row[\"fault_type\"],\n",
    "                        bearing_type=col.split(\"_\")[0]  # 当前样本的故障类型\n",
    "                    ), axis=1\n",
    "                )\n",
    "            if col==\"BA_time\":\n",
    "                # BA信号仅做低频滤波处理# BA信号预处理：滤波降噪和特征增强\n",
    "                group_df[proc_col+\"_lowfiltered\"] = group_df.apply(\n",
    "                    lambda row: butter_lowpass_filter(\n",
    "                        data=row[col],\n",
    "                        cutoff=100,  # 截止频率1kHz\n",
    "                        fs=fs,\n",
    "                        order=4\n",
    "                    ), axis=1\n",
    "                )\n",
    "                processed_signal_cols.append(proc_col+\"_lowfiltered\")\n",
    "            group_df[]=\n",
    "        if len(processed_signal_cols)==2:\n",
    "           \n",
    "            group_df[\"FUSED_time_added\"] = group_df.apply(\n",
    "                lambda row: add_sequences(group_df[processed_signal_cols[0]], group_df[processed_signal_cols[1]]), axis=1\n",
    "            )\n",
    "            processed_signal_cols.append(\"FUSED_time_added_21\")  # 后续会删除处理后的序列列\n",
    "            \n",
    "        if len(processed_signal_cols)==3:\n",
    "            group_df[\"FUSED_time_added\"] = group_df.apply(\n",
    "                lambda row: add_sequences(group_df[processed_signal_cols[0]], group_df[processed_signal_cols[1]],group_df[processed_signal_cols[2]]), axis=1\n",
    "            )\n",
    "            processed_signal_cols.append(\"FUSED_time_added_3\")  \n",
    "            group_df[\"FUSED_time_added\"] = group_df.apply(\n",
    "                lambda row: add_sequences(group_df[processed_signal_cols[0]], group_df[processed_signal_cols[1]]), axis=1\n",
    "            )\n",
    "            processed_signal_cols.append(\"FUSED_time_added_21\") \n",
    "            group_df[\"FUSED_time_added\"] = group_df.apply(\n",
    "                lambda row: add_sequences(group_df[processed_signal_cols[0]], group_df[processed_signal_cols[2]]), axis=1\n",
    "            )\n",
    "            processed_signal_cols.append(\"FUSED_time_added_22\") \n",
    "            \n",
    "        \n",
    "        # 子步骤3：不删除原始信号列，保留以备后续分析\n",
    "        #group_df = group_df.drop(columns=signal_cols)\n",
    "        \n",
    "        # 子步骤4：提取时域特征（为特征加idname前缀，避免后续合并冲突）\n",
    "        feature_dfs = []\n",
    "        for proc_col in processed_signal_cols:\n",
    "            sig_type = proc_col.split(\"_\")[0]\n",
    "            lowfil=proc_col.split(\"_\")[-1]  # 提取信号类型（DE/FE/BA）\n",
    "            \n",
    "                # BA信号同时提取频域特征                 # 提取BA频域特征（特别关注低频和旋转频率相关特征）\n",
    "            time_features = group_df[proc_col].apply(extract_time_features)\n",
    "            freq_features = group_df.apply(\n",
    "                    lambda row: extract_frequency_features(\n",
    "                        signal=row[proc_col],\n",
    "                        fs=fs,\n",
    "                        rpm=row[\"RPM\"]\n",
    "                    ), axis=1\n",
    "                )\n",
    "            physical_features=group_df[proc_col].apply(\n",
    "                    lambda row: extract_physical_features(\n",
    "                        signal=row[proc_col],\n",
    "                        fs=fs,\n",
    "                        rpm=row[\"RPM\"],\n",
    "                        fault_type=row[\"fault_type\"],\n",
    "                        bearing_type=sig_type\n",
    "                    ),axis=1\n",
    "                )\n",
    "            sample_entropy=group_df[proc_col].apply(extract_sample_entropy)\n",
    "            envelop_features=group_df[proc_col].apply(\n",
    "                    lambda row: extract_envelope_features(\n",
    "                        signal=row[proc_col],\n",
    "                        fs=fs\n",
    "                    ),axis=1    \n",
    "                )\n",
    "            if sig_type==\"BA\" and lowfil==\"lowfiltered\":\n",
    "                featureslow = pd.concat([time_features, freq_features], axis=1)\n",
    "            \n",
    "            \n",
    "            time_features = time_features.add_prefix(f\"{idname}_{sig_type}_processed\")  # 如X161_DE_mean\n",
    "            freq_features = freq_features.add_prefix(f\"{idname}_{sig_type}_processed_fft\")  # 如X161_DE_fft_max\n",
    "            physical_features=physical_features.add_prefix(f\"{idname}_{sig_type}_processed_phy\")\n",
    "            sample_entropy=sample_entropy.add_prefix(f\"{idname}_{sig_type}_processed_sampen\")\n",
    "            envelop_features=envelop_features.add_prefix(f\"{idname}_{sig_type}_processed_envelop\") \n",
    "            feature_dfs.extend([time_features, freq_features,physical_features,sample_entropy,envelop_features])\n",
    "            if featureslow:\n",
    "                featureslow = featureslow.add_prefix(f\"{idname}_{sig_type}_lowfiltered\")\n",
    "                feature_dfs.append(featureslow)\n",
    "        \n",
    "        # 合并特征与原始数据\n",
    "        group_df = pd.concat([group_df] + feature_dfs, axis=1)\n",
    "        \n",
    "        # 子步骤5：不删除处理后的原始信号列（保留以备后续分析）\n",
    "        #group_df = group_df.drop(columns=processed_signal_cols)\n",
    "        \n",
    "        # 子步骤6：标准化（同一idname的特征用同一标准化器）\n",
    "        num_cols = [col for col in group_df.columns if \n",
    "                   col in [\"RPM\", \"horsepower\"] or  # 原始数值列\n",
    "                   any(col.startswith(f\"{idname}_{t}_\") for t in [\"DE\", \"FE\", \"BA\"])]  # 提取的特征列\n",
    "        \n",
    "        if idname not in id_scaler_dict:\n",
    "            id_scaler_dict[idname] = StandardScaler()\n",
    "        group_df[num_cols] = id_scaler_dict[idname].fit_transform(group_df[num_cols])\n",
    "        \n",
    "        grouped_results.append(group_df)\n",
    "    \n",
    "    # 步骤3：合并所有分组结果，编码故障类型\n",
    "    if not grouped_results:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    final_df = pd.concat(grouped_results, ignore_index=True)\n",
    "    # 故障类型编码（B→0, IR→1, OR→2）\n",
    "    le = LabelEncoder()\n",
    "    final_df[\"fault_type_encoded\"] = le.fit_transform(final_df[\"fault_type\"])\n",
    "    # 新增数据类型标识（如12fe/48de）\n",
    "    final_df[\"data_type\"] = data_tag\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# ----------------------\n",
    "# 4. 批量预处理所有DataFrame\n",
    "# ----------------------\n",
    "def batch_smart_preprocess():\n",
    "    # 定义每个DataFrame对应的采样率（根据数据类型确定）\n",
    "    df_fs_bearing_map = {\n",
    "        \"df_12fe_b\": {\"fs\": 12000, \"bearing\": \"FE\"},\n",
    "        \"df_12fe_ir\": {\"fs\": 12000, \"bearing\": \"FE\"},\n",
    "        \"df_12fe_or\": {\"fs\": 12000, \"bearing\": \"FE\"},\n",
    "        \"df_48de_b\": {\"fs\": 48000, \"bearing\": \"DE\"},\n",
    "        \"df_48de_ir\": {\"fs\": 48000, \"bearing\": \"DE\"},\n",
    "        \"df_48de_or\": {\"fs\": 48000, \"bearing\": \"DE\"},\n",
    "        # 其他DataFrame...\n",
    "    }\n",
    "    \n",
    "    # 存储所有预处理后的DataFrame\n",
    "    preprocessed_all = []\n",
    "    \n",
    "    # 遍历所有生成的DataFrame（你的全局变量）\n",
    "    for df_name, info in df_fs_bearing_map.items():\n",
    "        fs = info[\"fs\"]\n",
    "        bearing_type = info[\"bearing\"]\n",
    "        # 检查变量是否存在\n",
    "        if df_name not in globals():\n",
    "            print(f\"跳过不存在的DataFrame: {df_name}\")\n",
    "            continue\n",
    "        \n",
    "        raw_df = globals()[df_name]\n",
    "        data_tag = df_name.split(\"_\")[1]  # 提取数据标识（如12fe/48de）\n",
    "        print(f\"\\n===== 开始预处理 {df_name}（采样率: {fs}Hz） =====\")\n",
    "        print(f\"原始数据形状: {raw_df.shape}，包含信号列: {[c for c in ['DE_time','FE_time','BA_time'] if c in raw_df.columns]}\")\n",
    "        \n",
    "        # 执行预处理\n",
    "        processed_df = preprocess_df(raw_df, data_tag, fs, bearing_type)\n",
    "        if not processed_df.empty:\n",
    "            preprocessed_all.append(processed_df)\n",
    "            print(f\"{df_name} 预处理完成，形状: {processed_df.shape}\")\n",
    "            \n",
    "            # （可选）保存单个预处理后的DataFrame\n",
    "            #save_path = f\"D:\\\\360极速浏览器下载\\\\data\\\\preprocessed\\\\{df_name}_preprocessed.csv\"\n",
    "            #processed_df.to_csv(save_path, index=False)\n",
    "            #print(f\"已保存至: {save_path}\")\n",
    "        else:\n",
    "            print(f\"{df_name} 预处理后无有效数据\")\n",
    "    \n",
    "    # 步骤5：合并所有预处理数据（用于后续建模）\n",
    "    if preprocessed_all:\n",
    "        combined_df = pd.concat(preprocessed_all, ignore_index=True)\n",
    "        combined_df = shuffle(combined_df, random_state=42)  # 打乱数据（避免类别集中）\n",
    "        \n",
    "        # 保存合并结果\n",
    "        combined_save_path = r\"D:\\360极速浏览器下载\\data\\preprocessed\\combined_smart_preprocessed.csv\"\n",
    "        combined_df.to_csv(combined_save_path, index=False)\n",
    "        \n",
    "        print(f\"\\n===== 批量预处理完成 =====\")\n",
    "        print(f\"合并后总数据形状: {combined_df.shape}\")\n",
    "        print(f\"合并数据保存至: {combined_save_path}\")\n",
    "        print(f\"故障类型分布:\\n{combined_df['fault_type'].value_counts()}\")\n",
    "        print(f\"数据类型分布:\\n{combined_df['data_type'].value_counts()}\")\n",
    "        \n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"\\n无任何有效预处理数据\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# ----------------------\n",
    "# 5. 执行预处理（直接运行）\n",
    "# ----------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 调用批量预处理函数，生成最终合并的预处理数据\n",
    "    final_preprocessed_df = batch_smart_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5baced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import logging\n",
    "from scipy.signal import butter, filtfilt\n",
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "# 配置日志\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=4):\n",
    "    \"\"\"低频滤波器，用于提取BA信号中的低频成分\"\"\"\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    y = filtfilt(b, a, data)\n",
    "    return y\n",
    "\n",
    "def extract_time_features(signal):\n",
    "    \"\"\"提取时域特征\"\"\"\n",
    "    if len(signal) == 0:\n",
    "        return pd.Series({\n",
    "            'rms': 0, 'peak': 0, 'mean': 0, 'std': 0,\n",
    "            'kurtosis': 0, 'skewness': 0, 'crest_factor': 0\n",
    "        })\n",
    "    \n",
    "    rms = np.sqrt(np.mean(np.square(signal)))\n",
    "    peak = np.max(np.abs(signal))\n",
    "    mean = np.mean(signal)\n",
    "    std = np.std(signal)\n",
    "    kurtosis = pd.Series(signal).kurtosis()\n",
    "    skewness = pd.Series(signal).skew()\n",
    "    crest_factor = peak / (rms + 1e-8)  # 避免除零\n",
    "    \n",
    "    return pd.Series({\n",
    "        'rms': rms,\n",
    "        'peak': peak,\n",
    "        'mean': mean,\n",
    "        'std': std,\n",
    "        'kurtosis': kurtosis,\n",
    "        'skewness': skewness,\n",
    "        'crest_factor': crest_factor\n",
    "    })\n",
    "\n",
    "def smart_preprocess(signal, fs, rpm, fault_type, bearing_type):\n",
    "    \"\"\"智能预处理函数，根据轴承类型和故障类型调整处理策略\"\"\"\n",
    "    # 基础滤波\n",
    "    filtered = butter_lowpass_filter(signal, cutoff=1000, fs=fs, order=3)\n",
    "    \n",
    "    # 根据轴承类型调整处理\n",
    "    if bearing_type in [\"DE\", \"FE\"]:\n",
    "        # 对轴承信号增强高频成分\n",
    "        if \"inner\" in fault_type.lower() or \"outer\" in fault_type.lower():\n",
    "            # 内圈或外圈故障，增强高频特征\n",
    "            high_freq_cutoff = min(2000, fs/2 * 0.9)  # 避免超过奈奎斯特频率\n",
    "            filtered = butter_lowpass_filter(filtered, cutoff=high_freq_cutoff, fs=fs, order=3)\n",
    "    elif bearing_type == \"BA\":\n",
    "        # 对基座信号更关注低频\n",
    "        filtered = butter_lowpass_filter(filtered, cutoff=500, fs=fs, order=4)\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "def extract_frequency_features(signal, fs, rpm):\n",
    "    \"\"\"提取频域特征，特别关注BA信号的低频特征\"\"\"\n",
    "    n = len(signal)\n",
    "    if n < 2:\n",
    "        return pd.Series({\n",
    "            'fft_max': 0, 'fft_mean': 0, 'rotation_freq_amp': 0,\n",
    "            'double_rotation_amp': 0, 'triple_rotation_amp': 0,\n",
    "            'low_freq_energy': 0, 'mid_low_freq_energy': 0\n",
    "        })\n",
    "    \n",
    "    freq = np.fft.fftfreq(n, 1/fs)[:n//2]\n",
    "    fft_values = np.abs(np.fft.fft(signal))[:n//2]\n",
    "    \n",
    "    # 计算旋转频率 (1x RPM)\n",
    "    rotation_freq = rpm / 60\n",
    "    \n",
    "    # 提取关键频率成分的幅值\n",
    "    def get_freq_amp(freq_band):\n",
    "        \"\"\"获取特定频率带内的最大幅值\"\"\"\n",
    "        mask = (freq >= freq_band[0]) & (freq <= freq_band[1])\n",
    "        return np.max(fft_values[mask]) if np.any(mask) else 0\n",
    "    \n",
    "    total_energy = np.sum(fft_values)\n",
    "    features = {\n",
    "        'fft_max': np.max(fft_values),\n",
    "        'fft_mean': np.mean(fft_values),\n",
    "        'rotation_freq_amp': get_freq_amp([rotation_freq*0.9, rotation_freq*1.1]),\n",
    "        'double_rotation_amp': get_freq_amp([rotation_freq*1.9, rotation_freq*2.1]),\n",
    "        'triple_rotation_amp': get_freq_amp([rotation_freq*2.9, rotation_freq*3.1]),\n",
    "        'low_freq_energy': np.sum(fft_values[freq <= 100]) / (total_energy + 1e-8) if total_energy > 0 else 0,\n",
    "        'mid_low_freq_energy': np.sum(fft_values[(freq > 100) & (freq <= 500)]) / (total_energy + 1e-8) if total_energy > 0 else 0\n",
    "    }\n",
    "    return pd.Series(features)\n",
    "\n",
    "def preprocess_df(df, data_tag, fs, bearing_type=None):\n",
    "    \"\"\"\n",
    "    处理同时包含DE、FE和BA信号的DataFrame，融合多测点特征，特别强化BA信号的系统级分析\n",
    "    \n",
    "    参数:\n",
    "        df (pd.DataFrame): 输入数据框，需包含\"idname\", \"RPM\", \"fault_type\"列，\n",
    "                          以及可选的\"DE_time\"、\"FE_time\"和\"BA_time\"列\n",
    "        data_tag (str): 数据类型标签，用于标识数据来源\n",
    "        fs (int/float): 采样频率\n",
    "        bearing_type (str, optional): 轴承类型，如\"DE\", \"FE\"或\"BA\"\n",
    "        \n",
    "    返回:\n",
    "        pd.DataFrame: 处理后的特征数据框，若处理失败则返回空数据框\n",
    "    \"\"\"\n",
    "    # 输入验证\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        logger.error(\"输入不是有效的DataFrame对象\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    required_base_cols = [\"idname\", \"RPM\", \"fault_type\"]\n",
    "    missing_cols = [col for col in required_base_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        logger.error(f\"缺少必要的基础列: {missing_cols}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # 检测各测点信号列\n",
    "    has_de = \"DE_time\" in df.columns\n",
    "    has_fe = \"FE_time\" in df.columns\n",
    "    has_ba = \"BA_time\" in df.columns  # BA信号：基座/电机底座振动信号\n",
    "    \n",
    "    if not (has_de or has_fe or has_ba):\n",
    "        logger.warning(\"无DE、FE或BA信号列，返回空DataFrame\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    logger.info(\n",
    "        f\"开始预处理数据，DE信号: {has_de}, FE信号: {has_fe}, BA信号: {has_ba}, \"\n",
    "        f\"数据标签: {data_tag}, 轴承类型: {bearing_type}\"\n",
    "    )\n",
    "    \n",
    "    grouped_results = []\n",
    "    id_scaler_dict = {}\n",
    "    total_groups = df[\"idname\"].nunique()\n",
    "    processed_groups = 0\n",
    "    \n",
    "    for idname, group_df in df.groupby(\"idname\"):\n",
    "        processed_groups += 1\n",
    "        logger.info(f\"处理组 {idname} ({processed_groups}/{total_groups})\")\n",
    "        \n",
    "        # 缺失值处理 - 保留关键列非空的行\n",
    "        required_cols = [\"RPM\", \"fault_type\", \"idname\"]\n",
    "        if has_de:\n",
    "            required_cols.append(\"DE_time\")\n",
    "        if has_fe:\n",
    "            required_cols.append(\"FE_time\")\n",
    "        if has_ba:\n",
    "            required_cols.append(\"BA_time\")\n",
    "        \n",
    "        # 检查并转换数据类型\n",
    "        valid_group = True\n",
    "        for col in required_cols:\n",
    "            if col in [\"DE_time\", \"FE_time\", \"BA_time\"]:\n",
    "                # 确保信号是数组格式\n",
    "                try:\n",
    "                    if not isinstance(group_df[col].iloc[0], (list, np.ndarray)):\n",
    "                        # 尝试将字符串转换为数组\n",
    "                        group_df[col] = group_df[col].apply(\n",
    "                            lambda x: np.fromstring(x.strip('[]'), sep=',') if isinstance(x, str) else x\n",
    "                        )\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"转换{col}列数据时出错: {str(e)}\")\n",
    "                    valid_group = False\n",
    "                    break\n",
    "        \n",
    "        if not valid_group:\n",
    "            logger.warning(f\"组 {idname} 数据转换失败，跳过处理\")\n",
    "            continue\n",
    "        \n",
    "        # 移除关键列有缺失值的行\n",
    "        initial_count = len(group_df)\n",
    "        group_df = group_df.dropna(subset=required_cols)\n",
    "        if len(group_df) < initial_count:\n",
    "            logger.warning(f\"组 {idname} 移除了 {initial_count - len(group_df)} 行缺失值数据\")\n",
    "        \n",
    "        if group_df.empty:\n",
    "            logger.warning(f\"组 {idname} 处理后为空，跳过\")\n",
    "            continue\n",
    "        \n",
    "        # 分别处理各测点信号\n",
    "        feature_dfs = []\n",
    "        \n",
    "        # 处理BA信号（重点关注低频特征）\n",
    "        if has_ba:\n",
    "            try:\n",
    "                # BA信号预处理：滤波降噪和特征增强\n",
    "                group_df[\"BA_time_filtered_low\"] = group_df.apply(\n",
    "                    lambda row: butter_lowpass_filter(row[\"BA_time\"], cutoff=100, fs=fs), axis=1\n",
    "                )\n",
    "                \n",
    "                # 提取BA时域特征\n",
    "                ba_time_features = group_df[\"BA_time_filtered_low\"].apply(extract_time_features)\n",
    "                ba_time_features = ba_time_features.add_prefix(\"BA_time_\")\n",
    "                \n",
    "                # 提取BA频域特征（特别关注低频和旋转频率相关特征）\n",
    "                ba_freq_features = group_df.apply(\n",
    "                    lambda row: extract_frequency_features(row[\"BA_time_filtered_low\"], fs, row[\"RPM\"]), axis=1\n",
    "                )\n",
    "                ba_freq_features = ba_freq_features.add_prefix(\"BA_freq_\")\n",
    "                \n",
    "                # 合并BA特征\n",
    "                ba_features = pd.concat([ba_time_features, ba_freq_features], axis=1)\n",
    "                feature_dfs.append(ba_features)\n",
    "                logger.info(f\"组 {idname} 成功提取BA特征 {len(ba_features.columns)} 个\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"处理组 {idname} 的BA信号时出错: {str(e)}\")\n",
    "        \n",
    "        # 处理DE信号\n",
    "        if has_de:\n",
    "            try:\n",
    "                # 预处理信号，使用传入的轴承类型参数\n",
    "                target_bearing = bearing_type if bearing_type == \"DE\" else \"DE\"\n",
    "                group_df[\"DE_time_processed\"] = group_df.apply(\n",
    "                    lambda row: smart_preprocess(\n",
    "                        signal=row[\"DE_time\"],\n",
    "                        fs=fs,\n",
    "                        rpm=row[\"RPM\"],\n",
    "                        fault_type=row[\"fault_type\"],\n",
    "                        bearing_type=target_bearing\n",
    "                    ), axis=1\n",
    "                )\n",
    "                \n",
    "                # 提取DE特征\n",
    "                de_time_features = group_df[\"DE_time_processed\"].apply(extract_time_features)\n",
    "                de_time_features = de_time_features.add_prefix(\"DE_time_\")\n",
    "                \n",
    "                de_freq_features = group_df.apply(\n",
    "                    lambda row: extract_frequency_features(row[\"DE_time_processed\"], fs, row[\"RPM\"]), axis=1\n",
    "                )\n",
    "                de_freq_features = de_freq_features.add_prefix(\"DE_freq_\")\n",
    "                \n",
    "                de_features = pd.concat([de_time_features, de_freq_features], axis=1)\n",
    "                feature_dfs.append(de_features)\n",
    "                logger.info(f\"组 {idname} 成功提取DE特征 {len(de_features.columns)} 个\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"处理组 {idname} 的DE信号时出错: {str(e)}\")\n",
    "        \n",
    "        # 处理FE信号\n",
    "        if has_fe:\n",
    "            try:\n",
    "                # 预处理信号，使用传入的轴承类型参数\n",
    "                target_bearing = bearing_type if bearing_type == \"FE\" else \"FE\"\n",
    "                group_df[\"FE_time_processed\"] = group_df.apply(\n",
    "                    lambda row: smart_preprocess(\n",
    "                        signal=row[\"FE_time\"],\n",
    "                        fs=fs,\n",
    "                        rpm=row[\"RPM\"],\n",
    "                        fault_type=row[\"fault_type\"],\n",
    "                        bearing_type=target_bearing\n",
    "                    ), axis=1\n",
    "                )\n",
    "                \n",
    "                # 提取FE特征\n",
    "                fe_time_features = group_df[\"FE_time_processed\"].apply(extract_time_features)\n",
    "                fe_time_features = fe_time_features.add_prefix(\"FE_time_\")\n",
    "                \n",
    "                fe_freq_features = group_df.apply(\n",
    "                    lambda row: extract_frequency_features(row[\"FE_time_processed\"], fs, row[\"RPM\"]), axis=1\n",
    "                )\n",
    "                fe_freq_features = fe_freq_features.add_prefix(\"FE_freq_\")\n",
    "                \n",
    "                fe_features = pd.concat([fe_time_features, fe_freq_features], axis=1)\n",
    "                feature_dfs.append(fe_features)\n",
    "                logger.info(f\"组 {idname} 成功提取FE特征 {len(fe_features.columns)} 个\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"处理组 {idname} 的FE信号时出错: {str(e)}\")\n",
    "        \n",
    "        # 多测点融合特征（BA与局部测点的关联分析）\n",
    "        if len(feature_dfs) >= 2 and has_ba:\n",
    "            try:\n",
    "                # 计算BA与DE/FE的特征比值，用于交叉验证\n",
    "                combined_features = pd.concat(feature_dfs, axis=1)\n",
    "                \n",
    "                # 振动幅值比（反映故障特征传递情况）\n",
    "                if has_de and 'DE_time_rms' in combined_features.columns:\n",
    "                    combined_features['BA_DE_amp_ratio'] = combined_features['BA_time_rms'] / (combined_features['DE_time_rms'] + 1e-8)\n",
    "                    combined_features['BA_DE_1x_ratio'] = combined_features['BA_freq_rotation_freq_amp'] / (combined_features['DE_freq_rotation_freq_amp'] + 1e-8)\n",
    "                \n",
    "                if has_fe and 'FE_time_rms' in combined_features.columns:\n",
    "                    combined_features['BA_FE_amp_ratio'] = combined_features['BA_time_rms'] / (combined_features['FE_time_rms'] + 1e-8)\n",
    "                    combined_features['BA_FE_1x_ratio'] = combined_features['BA_freq_rotation_freq_amp'] / (combined_features['FE_freq_rotation_freq_amp'] + 1e-8)\n",
    "                \n",
    "                # 系统级健康指标（基于BA低频特征）\n",
    "                if all(col in combined_features.columns for col in ['BA_freq_low_freq_energy', 'BA_time_rms', 'BA_freq_rotation_freq_amp']):\n",
    "                    combined_features['system_health_index'] = (\n",
    "                        0.4 * combined_features['BA_freq_low_freq_energy'] +\n",
    "                        0.3 * (1 / (combined_features['BA_time_rms'] + 1e-8)) +\n",
    "                        0.3 * (1 / (combined_features['BA_freq_rotation_freq_amp'] + 1e-8))\n",
    "                    )\n",
    "                \n",
    "                # 替换原有特征集\n",
    "                feature_dfs = [combined_features]\n",
    "                logger.info(f\"组 {idname} 成功生成多测点融合特征\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"计算组 {idname} 的多测点融合特征时出错: {str(e)}\")\n",
    "        \n",
    "        if not feature_dfs:\n",
    "            logger.warning(f\"组 {idname} 未能提取任何特征，跳过\")\n",
    "            continue\n",
    "        \n",
    "        # 合并特征\n",
    "        try:\n",
    "            features_combined = pd.concat(feature_dfs, axis=1)\n",
    "            group_df = pd.concat([group_df.reset_index(drop=True), features_combined.reset_index(drop=True)], axis=1)\n",
    "            # 移除处理后的信号列，释放内存\n",
    "            group_df = group_df.drop(\n",
    "                columns=[\"DE_time_processed\", \"FE_time_processed\", \"BA_time_filtered_low\"], \n",
    "                errors='ignore'\n",
    "            )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"组合组 {idname} 的特征时出错: {str(e)}\")\n",
    "            continue\n",
    "        \n",
    "        # 标准化数值特征\n",
    "        try:\n",
    "            # 确定需要标准化的列\n",
    "            num_cols = [col for col in group_df.columns if \n",
    "                       col in [\"RPM\", \"horsepower\"] or \n",
    "                       col.startswith(\"DE_\") or \n",
    "                       col.startswith(\"FE_\") or\n",
    "                       col.startswith(\"BA_\") or\n",
    "                       col.startswith(\"system_\")]\n",
    "            \n",
    "            if num_cols:\n",
    "                if idname not in id_scaler_dict:\n",
    "                    id_scaler_dict[idname] = StandardScaler()\n",
    "                \n",
    "                # 处理可能的无穷值或NaN\n",
    "                group_df[num_cols] = group_df[num_cols].replace([np.inf, -np.inf], np.nan)\n",
    "                # 使用列的中位数填充缺失值，更稳健\n",
    "                group_df[num_cols] = group_df[num_cols].fillna(group_df[num_cols].median())\n",
    "                \n",
    "                # 执行标准化\n",
    "                group_df[num_cols] = id_scaler_dict[idname].fit_transform(group_df[num_cols])\n",
    "                logger.info(f\"组 {idname} 标准化了 {len(num_cols)} 个特征列\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"标准化组 {idname} 的特征时出错: {str(e)}\")\n",
    "            continue\n",
    "        \n",
    "        grouped_results.append(group_df)\n",
    "    \n",
    "    # 合并所有组并进行最终处理\n",
    "    if not grouped_results:\n",
    "        logger.warning(\"没有成功处理的组，返回空DataFrame\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        final_df = pd.concat(grouped_results, ignore_index=True)\n",
    "        logger.info(f\"所有组处理完成，总记录数: {len(final_df)}\")\n",
    "        \n",
    "        # 编码故障类型\n",
    "        le = LabelEncoder()\n",
    "        final_df[\"fault_type_encoded\"] = le.fit_transform(final_df[\"fault_type\"])\n",
    "        logger.info(f\"已编码故障类型，共 {len(le.classes_)} 种类型: {', '.join(le.classes_)}\")\n",
    "        \n",
    "        # 添加数据类型标签和轴承类型\n",
    "        final_df[\"data_type\"] = data_tag\n",
    "        if bearing_type:\n",
    "            final_df[\"bearing_type\"] = bearing_type\n",
    "        \n",
    "        # 清理原始信号列，保留特征列\n",
    "        cols_to_drop = []\n",
    "        if has_de: cols_to_drop.append(\"DE_time\")\n",
    "        if has_fe: cols_to_drop.append(\"FE_time\")\n",
    "        if has_ba: cols_to_drop.append(\"BA_time\")\n",
    "        final_df = final_df.drop(columns=cols_to_drop, errors='ignore')\n",
    "        \n",
    "        return final_df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"合并结果时出错: {str(e)}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def batch_smart_preprocess(df_fs_bearing_map: Optional[Dict] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    批量预处理多个DataFrame的轴承振动信号数据\n",
    "    \n",
    "    参数:\n",
    "        df_fs_bearing_map: 包含DataFrame名称、采样频率和轴承类型的字典\n",
    "        \n",
    "    返回:\n",
    "        合并后的预处理数据\n",
    "    \"\"\"\n",
    "    # 默认的DataFrame配置映射\n",
    "    default_map = {\n",
    "        \"df_12fe_b\": {\"fs\": 12000, \"bearing\": \"FE\"},\n",
    "        \"df_12fe_ir\": {\"fs\": 12000, \"bearing\": \"FE\"},\n",
    "        \"df_12fe_or\": {\"fs\": 12000, \"bearing\": \"FE\"},\n",
    "        \"df_48de_b\": {\"fs\": 48000, \"bearing\": \"DE\"},\n",
    "        \"df_48de_ir\": {\"fs\": 48000, \"bearing\": \"DE\"},\n",
    "        \"df_48de_or\": {\"fs\": 48000, \"bearing\": \"DE\"},\n",
    "        # 可以添加更多DataFrame配置\n",
    "    }\n",
    "    \n",
    "    # 使用传入的映射或默认映射\n",
    "    processing_map = df_fs_bearing_map if df_fs_bearing_map is not None else default_map\n",
    "    preprocessed_all = []\n",
    "    \n",
    "    # 获取当前全局变量，用于查找DataFrame\n",
    "    current_globals = globals()\n",
    "    \n",
    "    for df_name, info in processing_map.items():\n",
    "        try:\n",
    "            fs = info[\"fs\"]\n",
    "            bearing_type = info[\"bearing\"]\n",
    "            \n",
    "            if df_name not in current_globals:\n",
    "                logger.warning(f\"DataFrame '{df_name}' 不存在于全局变量中，跳过处理\")\n",
    "                continue\n",
    "            \n",
    "            raw_df = current_globals[df_name]\n",
    "            \n",
    "            # 验证是否为有效的DataFrame\n",
    "            if not isinstance(raw_df, pd.DataFrame):\n",
    "                logger.warning(f\"全局变量 '{df_name}' 不是有效的DataFrame，跳过处理\")\n",
    "                continue\n",
    "                \n",
    "            # 提取数据标签（例如从\"df_12fe_b\"中提取\"12fe\"）\n",
    "            data_tag = \"_\".join(df_name.split(\"_\")[1:-1]) if len(df_name.split(\"_\")) >= 3 else df_name\n",
    "            \n",
    "            logger.info(f\"开始处理 {df_name}，采样频率: {fs}, 轴承类型: {bearing_type}\")\n",
    "            \n",
    "            # 预处理数据\n",
    "            processed_df = preprocess_df(raw_df, data_tag, fs, bearing_type)\n",
    "            \n",
    "            if not processed_df.empty:\n",
    "                preprocessed_all.append(processed_df)\n",
    "                logger.info(f\"完成 {df_name} 处理，生成 {len(processed_df)} 条记录\")\n",
    "            else:\n",
    "                logger.warning(f\"{df_name} 处理后为空，未添加到结果集中\")\n",
    "                \n",
    "        except KeyError as e:\n",
    "            logger.error(f\"{df_name} 配置信息不完整，缺少键: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"处理 {df_name} 时发生错误: {str(e)}\")\n",
    "    \n",
    "    # 合并所有预处理数据\n",
    "    if not preprocessed_all:\n",
    "        logger.warning(\"没有成功预处理的DataFrame，返回空DataFrame\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        combined_df = pd.concat(preprocessed_all, ignore_index=True)\n",
    "        logger.info(f\"所有DataFrame处理完成，总记录数: {len(combined_df)}\")\n",
    "        return combined_df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"合并所有预处理数据时出错: {str(e)}\")\n",
    "        return pd.DataFrame()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
